Subword-based tokenization
Subword-based tokenization is a solution between word and character-based tokenization. ğŸ˜ The main idea is to solve the issues faced by word-based tokenization (very large vocabulary size, large number of OOV tokens, and different meaning of very similar words) and character-based tokenization (very long sequences and less meaningful individual tokens).
The subword-based tokenization algorithms do not split the frequently used words into smaller subwords. It rather splits the rare words into smaller meaningful subwords. For example, â€œboyâ€ is not split but â€œboysâ€ is split into â€œboyâ€ and â€œsâ€. This helps the model learn that the word â€œboysâ€ is formed using the word â€œboyâ€ with slightly different meanings but the same root word.
Some of the popular subword tokenization algorithms are WordPiece, Byte-Pair Encoding (BPE), Unigram, and SentencePiece
